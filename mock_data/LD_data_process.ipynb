{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "data_dir = \"./LD_data/\"\n",
    "# Flags\n",
    "sequences_exist = True\n",
    "model_exist = True\n",
    "distance_exist = True\n",
    "adjacency_exist = True\n",
    "# Seeds\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike points location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 786 * (index, name, id, lat, lon, capacity)\n",
    "df_locs = pd.read_csv(data_dir+'org_data/bike_point_locations.csv')\n",
    "# GeoDataFrame 786 * (index, name, id, capacity, geometry) proj='epsg:27700'\n",
    "gdf_locs = gpd.read_file(data_dir+'intermediate_results/bike_point_locations_saved.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin-destination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 8,115,378 * (time, index_start, index_end, count)\n",
    "# df_od (index_start/index_end) -> df_locs/gdf_locs (index)\n",
    "df_od = pd.read_csv(data_dir+\"org_data/bike_od.csv\")\n",
    "# Ndarray (786,786) - Daily Average (index) -> df_locs/gdf_locs (index)\n",
    "od_mx = np.load(data_dir+\"final_input/bike_od_mx.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoDataFrame 786 * (index, name, id, capacity, geometry)\n",
    "gdf_BD = gpd.read_file(data_dir+\"intermediate_results/gdf_BD.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame (Group-Category-Class)   (class_code, group, category, class, group_des, category_des, class_des)\n",
    "df_poiclass = pd.read_csv(data_dir+\"org_data/POI_CLASSIFICATION.csv\")\n",
    "# GeoDataFrame 490,626 * (pointx_cla, geometry)\n",
    "# pointx_cla -> class_code\n",
    "gdf_poi = gpd.read_file(data_dir+\"intermediate_results/poi.shp\")\n",
    "# Merge GeoDataFrame 490,626 * (class, class_des, geometry)\n",
    "gdf_poi = gdf_poi.merge(df_poiclass, left_on='pointx_cla', right_on='class_code', how='left')[[\"class\",\"class_des\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 786 * (cat1, cat2, ..., cat8)\n",
    "df_LUarea = pd.read_csv(data_dir+\"final_input/df_LUarea.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences_by_distancegreedy(gdf_tz, gdf_poi, minpois = 1):\n",
    "    sequences = {}\n",
    "    df_join = sjoin(gdf_poi, gdf_tz, how=\"inner\",op=\"within\")\n",
    "    for tz_ind in tqdm.tqdm(df_join.index_right.unique()):\n",
    "        tz_pois = df_join[df_join.index_right == tz_ind].reset_index()\n",
    "        if tz_pois.shape[0] > minpois:\n",
    "            pnt_num = tz_pois.shape[0]\n",
    "            z = np.array([[complex(g.x, g.y) for g in tz_pois.geometry]])\n",
    "            dismat = abs(z.T-z)\n",
    "            visited = list(np.unravel_index(np.argmax(dismat, axis=None), dismat.shape))\n",
    "            # list of to be visited points\n",
    "            not_visited = [x for x in range(pnt_num) if x not in visited]\n",
    "            np.random.shuffle(not_visited)\n",
    "            while not_visited:\n",
    "                to_be_visit = not_visited.pop()\n",
    "                if len(visited) == 2:\n",
    "                    visited.insert(1, to_be_visit)\n",
    "                    pass\n",
    "                else:\n",
    "                    search_bound = list(zip(visited[0:-1], visited[1:]))\n",
    "                    dis = [dismat[to_be_visit, x]+dismat[to_be_visit, y]\n",
    "                           for x, y in search_bound]\n",
    "                    insert_place = dis.index(min(dis))+1\n",
    "                    visited.insert(insert_place, to_be_visit)\n",
    "            sequences[tz_ind] = tz_pois.loc[visited, \"class\"].values\n",
    "    return sequences\n",
    "\n",
    "if not sequences_exist:\n",
    "    sequences = get_sequences_by_distancegreedy(gdf_BD.set_index('index'),gdf_poi)\n",
    "    np.save(data_dir+\"intermediate_results/Sequences_greedy.npy\",sequences)\n",
    "else:\n",
    "    sequences = np.load(data_dir+\"intermediate_results/Sequences_greedy.npy\",allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_exist:\n",
    "    corpus = [TaggedDocument([str(x) for x in words], [f'd{idx}'])for idx, words in sequences.items()]\n",
    "    model = gensim.models.doc2vec.Doc2Vec(dm=1,vector_size=72,dm_mean=1,window=5,dbow_words=1,min_count=1,epochs=100,seed=1,workers=1)\n",
    "    model.build_vocab(corpus)\n",
    "    model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    model.save(data_dir+\"intermediate_results/doc2vec_model\")\n",
    "else:\n",
    "    model = gensim.models.doc2vec.Doc2Vec.load(data_dir+\"intermediate_results/doc2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_exist:\n",
    "    df_zonevec = pd.DataFrame.from_dict({'index': sequences.keys()})\n",
    "    i = 1\n",
    "    for v in model.dv.vectors.T:\n",
    "        df_zonevec[f\"ZoneVec_{i}\"] = v\n",
    "        i += 1\n",
    "    df_zonevec = df_zonevec.set_index(\"index\").sort_index()\n",
    "    df_zonevec.to_csv(data_dir+\"final_input/df_zonevec.csv\")\n",
    "else:\n",
    "    df_zonevec = pd.read_csv(data_dir+\"final_input/df_zonevec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not distance_exist:\n",
    "    df_dis = gdf_BD.geometry.centroid.apply(lambda g:gdf_BD.geometry.centroid.distance(g))\n",
    "    df_dis.round(0).to_csv(data_dir+\"final_input/df_dis.csv\",index=False)\n",
    "else:\n",
    "    df_dis = pd.read_csv(data_dir+\"final_input/df_dis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency List [[index,index,weight],...]\n",
    "if not adjacency_exist:\n",
    "    ls_edge = []\n",
    "    for _, row in gdf_BD.iterrows():\n",
    "        neighbors = gdf_BD[~gdf_BD.geometry.disjoint(row.geometry)]['index'].tolist()\n",
    "        for i in neighbors:\n",
    "            if row['index'] < i:\n",
    "                a = [row['index'],i,1]\n",
    "                ls_edge.append(a)\n",
    "    with open(data_dir+\"final_input/ls_edge.pkl\",\"wb\") as f:\n",
    "        pickle.dump(ls_edge,f)\n",
    "else:\n",
    "    with open(data_dir+\"final_input/ls_edge.pkl\",\"rb\") as f:\n",
    "        ls_edge=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary (input - interaction - output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ⅰ - input (property - Doc2Vec Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 786 * 72\n",
    "# df_zonevec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ⅱ - interaction (flow/distance/adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow (786,786) Daily Average\n",
    "# od_mx\n",
    "# Distance-decay (786,786)\n",
    "# df_dis\n",
    "# Adjacency [2150*[index,index,1]]\n",
    "# ls_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ⅲ - output (urban function - LU area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Land Use (786,8)\n",
    "# df_LUarea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GCN",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
